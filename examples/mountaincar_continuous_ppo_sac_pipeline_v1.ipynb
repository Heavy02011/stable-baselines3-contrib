{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MountainCarContinuous-v0 – PPO vs SAC Pipeline\n",
    "\n",
    "End-to-end Pipeline:\n",
    "1. Environment-Setup\n",
    "2. Hyperparameter-Definition\n",
    "3. Training von PPO und SAC\n",
    "4. Evaluation und Vergleich\n",
    "5. Video-Recording der Policies\n",
    "6. Side-by-Side-Merge mit ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# filename: mountaincar_continuous_ppo_sac_pipeline_v1.ipynb\n",
    "# model: GPT-5.1 Thinking – prompt: PPO vs SAC MountainCarContinuous pipeline notebook\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO, SAC\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    \"\"\"Create a monitored MountainCarContinuous-v0 environment.\"\"\"\n",
    "    env = gym.make(\"MountainCarContinuous-v0\")\n",
    "    env = Monitor(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "def record_video(model, video_folder, video_name, max_steps=999):\n",
    "    \"\"\"Record rollout of a trained model as MP4 using VecVideoRecorder.\"\"\"\n",
    "    os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "    def _make_env():\n",
    "        return gym.make(\"MountainCarContinuous-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "    vec_env = DummyVecEnv([_make_env])\n",
    "    vec_env = VecVideoRecorder(\n",
    "        vec_env,\n",
    "        video_folder=video_folder,\n",
    "        record_video_trigger=lambda step: step == 0,\n",
    "        video_length=max_steps,\n",
    "        name_prefix=video_name,\n",
    "    )\n",
    "\n",
    "    obs = vec_env.reset()\n",
    "    for _ in range(max_steps):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, _, dones, _ = vec_env.step(action)\n",
    "        if dones[0]:\n",
    "            break\n",
    "\n",
    "    vec_env.close()\n",
    "\n",
    "\n",
    "def merge_videos_side_by_side(\n",
    "    input_left,\n",
    "    input_right,\n",
    "    output_path,\n",
    "    label_left=\"PPO\",\n",
    "    label_right=\"SAC\",\n",
    "):\n",
    "    \"\"\"Merge two videos side by side using ffmpeg with simple labels.\"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_left,\n",
    "        \"-i\", input_right,\n",
    "        \"-filter_complex\",\n",
    "        (\n",
    "            \"[0:v]drawtext=text='{label_left}':x=20:y=20:fontsize=36:fontcolor=white[v0];\"\n",
    "            \"[1:v]drawtext=text='{label_right}':x=20:y=20:fontsize=36:fontcolor=white[v1];\"\n",
    "            \"[v0][v1]hstack=inputs=2[v]\"\n",
    "        ),\n",
    "        \"-map\", \"[v]\",\n",
    "        \"-y\",\n",
    "        output_path,\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# filename: mountaincar_continuous_ppo_sac_pipeline_v1.ipynb\n",
    "# model: GPT-5.1 Thinking – prompt: PPO vs SAC MountainCarContinuous pipeline notebook\n",
    "\n",
    "TOTAL_TIMESTEPS = 300_000\n",
    "VIDEO_FOLDER = \"videos\"\n",
    "\n",
    "ppo_kwargs = dict(\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.0,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    policy_kwargs=dict(net_arch=[64, 64]),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "sac_kwargs = dict(\n",
    "    learning_rate=3e-4,\n",
    "    buffer_size=100_000,\n",
    "    batch_size=256,\n",
    "    tau=0.005,\n",
    "    gamma=0.99,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    ent_coef=\"auto\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# filename: mountaincar_continuous_ppo_sac_pipeline_v1.ipynb\n",
    "# model: GPT-5.1 Thinking – prompt: PPO vs SAC MountainCarContinuous pipeline notebook\n",
    "\n",
    "ppo_env = DummyVecEnv([make_env])\n",
    "ppo_model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    ppo_env,\n",
    "    **ppo_kwargs,\n",
    ")\n",
    "ppo_model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
    "ppo_model.save(\"ppo_mountaincar_continuous\")\n",
    "ppo_env.close()\n",
    "\n",
    "sac_env = DummyVecEnv([make_env])\n",
    "sac_model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    sac_env,\n",
    "    **sac_kwargs,\n",
    ")\n",
    "sac_model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
    "sac_model.save(\"sac_mountaincar_continuous\")\n",
    "sac_env.close()\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# filename: mountaincar_continuous_ppo_sac_pipeline_v1.ipynb\n",
    "# model: GPT-5.1 Thinking – prompt: PPO vs SAC MountainCarContinuous pipeline notebook\n",
    "\n",
    "eval_env = gym.make(\"MountainCarContinuous-v0\")\n",
    "\n",
    "ppo_mean_reward, ppo_std_reward = evaluate_policy(\n",
    "    ppo_model,\n",
    "    eval_env,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "sac_mean_reward, sac_std_reward = evaluate_policy(\n",
    "    sac_model,\n",
    "    eval_env,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "eval_env.close()\n",
    "\n",
    "print(f\"PPO mean reward: {ppo_mean_reward:.2f} ± {ppo_std_reward:.2f}\")\n",
    "print(f\"SAC mean reward: {sac_mean_reward:.2f} ± {sac_std_reward:.2f}\")\n",
    "\n",
    "algorithms = [\"PPO\", \"SAC\"]\n",
    "mean_rewards = [ppo_mean_reward, sac_mean_reward]\n",
    "std_rewards = [ppo_std_reward, sac_std_reward]\n",
    "\n",
    "plt.figure()\n",
    "x_positions = np.arange(len(algorithms))\n",
    "plt.bar(x_positions, mean_rewards, yerr=std_rewards, capsize=5)\n",
    "plt.xticks(x_positions, algorithms)\n",
    "plt.ylabel(\"Mean reward (20 episodes)\")\n",
    "plt.title(\"MountainCarContinuous-v0: PPO vs SAC\")\n",
    "plt.show()\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# filename: mountaincar_continuous_ppo_sac_pipeline_v1.ipynb\n",
    "# model: GPT-5.1 Thinking – prompt: PPO vs SAC MountainCarContinuous pipeline notebook\n",
    "\n",
    "os.makedirs(VIDEO_FOLDER, exist_ok=True)\n",
    "\n",
    "ppo_video_path = os.path.join(VIDEO_FOLDER, \"ppo_mountaincar_continuous.mp4\")\n",
    "sac_video_path = os.path.join(VIDEO_FOLDER, \"sac_mountaincar_continuous.mp4\")\n",
    "\n",
    "record_video(\n",
    "    model=ppo_model,\n",
    "    video_folder=VIDEO_FOLDER,\n",
    "    video_name=\"ppo_mountaincar_continuous\",\n",
    "    max_steps=999,\n",
    ")\n",
    "\n",
    "record_video(\n",
    "    model=sac_model,\n",
    "    video_folder=VIDEO_FOLDER,\n",
    "    video_name=\"sac_mountaincar_continuous\",\n",
    "    max_steps=999,\n",
    ")\n",
    "\n",
    "print(\"Videos gespeichert in:\", os.path.abspath(VIDEO_FOLDER))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# filename: mountaincar_continuous_ppo_sac_pipeline_v1.ipynb\n",
    "# model: GPT-5.1 Thinking – prompt: PPO vs SAC MountainCarContinuous pipeline notebook\n",
    "\n",
    "side_by_side_output = os.path.join(\n",
    "    VIDEO_FOLDER,\n",
    "    \"mountaincar_ppo_vs_sac_side_by_side.mp4\",\n",
    ")\n",
    "\n",
    "merge_videos_side_by_side(\n",
    "    input_left=ppo_video_path,\n",
    "    input_right=sac_video_path,\n",
    "    output_path=side_by_side_output,\n",
    "    label_left=\"PPO\",\n",
    "    label_right=\"SAC\",\n",
    ")\n",
    "\n",
    "print(\"Side-by-side Video erstellt:\", os.path.abspath(side_by_side_output))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}